{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import charade\n",
    "import math\n",
    "import unidecode\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect('db.duckdb', read_only=False)\n",
    "print(conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect('db.duckdb', read_only=False)\n",
    "\n",
    "for i in conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist():\n",
    "    conn.execute(f\"DROP table {i}\")\n",
    "print(conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train1', 'train2', 'train3', 'train4', 'train5', 'train6', 'train7', 'train8']\n"
     ]
    }
   ],
   "source": [
    "# set path for data\n",
    "data_root = 'imdb'\n",
    "train_table_name_list = []\n",
    "for fname in os.listdir(data_root):\n",
    "    if fname.startswith('train'):\n",
    "        # load train csv in pandas df\n",
    "        path = os.path.join(data_root, fname)\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # register and create in duckdb\n",
    "        new_name = ''.join(fname.split('.')[0].split('-'))\n",
    "        train_table_name_list.append(new_name)\n",
    "        conn.register(new_name, df)\n",
    "        \n",
    "print(conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing train tables from DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7959, 9)\n"
     ]
    }
   ],
   "source": [
    "tables = conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist()\n",
    "frames = []\n",
    "for i in tables:\n",
    "    frames.append(conn.execute(f\"SELECT * FROM {i}\").fetchdf())\n",
    "full_train_df = pd.concat(frames)\n",
    " \n",
    "print(full_train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Getting data from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/casbertrams/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import gzip\n",
    "from io import StringIO\n",
    "\n",
    "title_basics_gz_url = 'https://datasets.imdbws.com/title.basics.tsv.gz'\n",
    "try:\n",
    "    response = requests.get(title_basics_gz_url)\n",
    "    unzipped = gzip.decompress(response.content).decode()\n",
    "    title_basics_df = pd.read_csv(StringIO(unzipped), sep='\\t', header=None)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>4</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy,Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0     tconst titleType            primaryTitle           originalTitle  \\\n",
       "1  tt0000001     short              Carmencita              Carmencita   \n",
       "2  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "3  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "4  tt0000004     short             Un bon bock             Un bon bock   \n",
       "5  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "0 isAdult startYear endYear runtimeMinutes                    genres  \n",
       "1       0      1894      \\N              1         Documentary,Short  \n",
       "2       0      1892      \\N              5           Animation,Short  \n",
       "3       0      1892      \\N              4  Animation,Comedy,Romance  \n",
       "4       0      1892      \\N             12           Animation,Short  \n",
       "5       0      1893      \\N              1              Comedy,Short  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_header = title_basics_df.iloc[0] \n",
    "title_basics_df = title_basics_df[1:] #take the data less the header row\n",
    "title_basics_df.columns = new_header #set the header row as the df header\n",
    "title_basics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Filter imdb dataset for only the relevant tconsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 379 ms, sys: 2.8 ms, total: 382 ms\n",
      "Wall time: 379 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "relevant_tconsts = full_train_df['tconst']\n",
    "mask = title_basics_df['tconst'].isin(relevant_tconsts)\n",
    "relevant_title_basics_df = title_basics_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           tconst titleType                                   primaryTitle  \\\n",
      "9238     tt0009369     movie                                         Mickey   \n",
      "10459    tt0010600     movie                                       The Doll   \n",
      "11279    tt0011439     movie                              The Mark of Zorro   \n",
      "11447    tt0011607     movie                             The Parson's Widow   \n",
      "11676    tt0011841     movie                                  Way Down East   \n",
      "...            ...       ...                                            ...   \n",
      "8744873  tt9850344     movie                                    Night Shift   \n",
      "8744892  tt9850386     movie  The Bee Gees: How Can You Mend a Broken Heart   \n",
      "8768128  tt9900782     movie                                         Kaithi   \n",
      "8770015  tt9904802     movie                                    Enemy Lines   \n",
      "8772977  tt9911196     movie                            The Marriage Escape   \n",
      "\n",
      "0                                        originalTitle isAdult startYear  \\\n",
      "9238                                            Mickey       0      1918   \n",
      "10459                                        Die Puppe       0      1919   \n",
      "11279                                The Mark of Zorro       0      1920   \n",
      "11447                                       Prästänkan       0      1920   \n",
      "11676                                    Way Down East       0      1920   \n",
      "...                                                ...     ...       ...   \n",
      "8744873                                         Police       0      2020   \n",
      "8744892  The Bee Gees: How Can You Mend a Broken Heart       0      2020   \n",
      "8768128                                         Kaithi       0      2019   \n",
      "8770015                                    Enemy Lines       0      2020   \n",
      "8772977                 De beentjes van Sint-Hildegard       0      2020   \n",
      "\n",
      "0       endYear runtimeMinutes                       genres  \n",
      "9238         \\N             93                 Comedy,Drama  \n",
      "10459        \\N             66               Comedy,Fantasy  \n",
      "11279        \\N             79    Adventure,Romance,Western  \n",
      "11447        \\N             94          Comedy,Drama,Horror  \n",
      "11676        \\N            145                Drama,Romance  \n",
      "...         ...            ...                          ...  \n",
      "8744873      \\N             98                  Crime,Drama  \n",
      "8744892      \\N            111  Biography,Documentary,Music  \n",
      "8768128      \\N            145        Action,Crime,Thriller  \n",
      "8770015      \\N             92                          War  \n",
      "8772977      \\N            103                 Comedy,Drama  \n",
      "\n",
      "[7959 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(relevant_title_basics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating single column dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tconst_list = full_train_df['tconst'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN present: False\n"
     ]
    }
   ],
   "source": [
    "primary_title = []\n",
    "for i in range(len(full_train_df)):\n",
    "    primary_title.append(unidecode.unidecode(full_train_df.iloc[i]['primaryTitle']))\n",
    "primary_title_df = pd.DataFrame(primary_title, index=full_train_df['tconst'], columns=['primary_title'])\n",
    "\n",
    "print(f\"NaN present: {primary_title_df.isnull().values.any()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN present: False\n"
     ]
    }
   ],
   "source": [
    "original_title = []\n",
    "for i in range(len(full_train_df)):\n",
    "    curr = full_train_df.iloc[i]['originalTitle']\n",
    "    curr_primary_title = full_train_df.iloc[i]['primaryTitle']\n",
    "    if isinstance(curr, str):\n",
    "        original_title.append(unidecode.unidecode(curr))\n",
    "    else:\n",
    "        original_title.append('')\n",
    "original_title_df = pd.DataFrame(original_title, index=full_train_df['tconst'], columns=['original_title'])\n",
    "print(f\"NaN present: {original_title_df.isnull().values.any()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN present: False\n"
     ]
    }
   ],
   "source": [
    "start_year = []\n",
    "for i in range(len(full_train_df)):\n",
    "    curr = full_train_df.iloc[i]['startYear']\n",
    "    if curr == \"\\\\N\":\n",
    "#         curr_tconst = full_train_df.iloc[i]['tconst']\n",
    "#         imdb_year = int(relevant_title_basics_df[relevant_title_basics_df['tconst'] == curr_tconst]['startYear'].values[0])\n",
    "#         start_year.append(imdb_year)\n",
    "        start_year.append(int())\n",
    "    else:\n",
    "        start_year.append(int(curr))\n",
    "start_year_df = pd.DataFrame(start_year, index=full_train_df['tconst'], columns=['start_year'])\n",
    "print(f\"NaN present: {start_year_df.isnull().values.any()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN present: False\n"
     ]
    }
   ],
   "source": [
    "end_year = []\n",
    "for i in range(len(full_train_df)):\n",
    "    curr = full_train_df.iloc[i]['endYear']\n",
    "    if curr == \"\\\\N\":\n",
    "        end_year.append(int())\n",
    "    else:\n",
    "        end_year.append(int(curr))\n",
    "end_year_df = pd.DataFrame(end_year, index=full_train_df['tconst'], columns=['end_year'])\n",
    "print(f\"NaN present: {end_year_df.isnull().values.any()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN present: False\n"
     ]
    }
   ],
   "source": [
    "runtime_minutes = []\n",
    "for i in range(len(full_train_df)):\n",
    "    curr = full_train_df.iloc[i]['runtimeMinutes']\n",
    "    if curr == \"\\\\N\":\n",
    "#         curr_tconst = full_train_df.iloc[i]['tconst']\n",
    "#         imdb_runtime = relevant_title_basics_df[relevant_title_basics_df['tconst'] == curr_tconst]['runtimeMinutes'].values[0]\n",
    "#         if imdb_runtime == \"\\\\N\":\n",
    "#             runtime_minutes.append(int())\n",
    "#         else:\n",
    "#             runtime_minutes.append(int(imdb_runtime))\n",
    "        runtime_minutes.append(int())\n",
    "    else:\n",
    "        runtime_minutes.append(int(curr))\n",
    "runtime_df = pd.DataFrame(runtime_minutes, index=full_train_df['tconst'], columns=['runtime_minutes'])\n",
    "print(f\"NaN present: {runtime_df.isnull().values.any()}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN present: False\n"
     ]
    }
   ],
   "source": [
    "num_votes = []\n",
    "for i in range(len(full_train_df)):\n",
    "    curr = full_train_df.iloc[i]['numVotes']\n",
    "    if curr == 'nan' or curr == \"NaN\" or math.isnan(curr):\n",
    "#         curr_tconst = full_train_df.iloc[i]['tconst']\n",
    "#         imdb_num_votes = relevant_title_basics_df[relevant_title_basics_df['tconst'] == curr_tconst]['runtimeMinutes'].values[0]\n",
    "        num_votes.append(int())\n",
    "    else:\n",
    "        num_votes.append(int(curr))\n",
    "\n",
    "num_votes_df = pd.DataFrame(num_votes, index=full_train_df['tconst'], columns=['num_votes'])\n",
    "num_votes_df = num_votes_df.fillna(int())\n",
    "print(f\"NaN present: {num_votes_df.isnull().values.any()}\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values: [ True False]\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.DataFrame(full_train_df['label'].tolist(), index=full_train_df['tconst'], columns=[\"label\"])\n",
    "print(f\"Distinct values: {label_df['label'].unique()}\")\n",
    "labels = full_train_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new tables in duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect\n",
    "db_path = os.path.join('db', 'db.duckdb')\n",
    "conn = duckdb.connect(db_path, read_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove existing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist():\n",
    "    if i.startswith('train'):\n",
    "        conn.execute(f\"DROP VIEW {i}\")\n",
    "\n",
    "print(conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'tconst', 'primaryTitle', 'originalTitle', 'startYear',\n",
      "       'endYear', 'runtimeMinutes', 'numVotes', 'label'],\n",
      "      dtype='object')\n",
      "7959\n",
      "7959\n",
      "7959\n",
      "7959\n",
      "7959\n",
      "7959\n",
      "7959\n"
     ]
    }
   ],
   "source": [
    "print(full_train_df.columns)\n",
    "\n",
    "print(len(primary_title))\n",
    "print(len(original_title_df))\n",
    "print(len(start_year_df))\n",
    "print(len(end_year_df))\n",
    "print(len(runtime_df))\n",
    "print(len(num_votes_df))\n",
    "print(len(label_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating primary_title table\n",
      "   primary_title did not exist\n",
      "Creating original_title table\n",
      "   original_title did not exist\n",
      "Creating start_year table\n",
      "   start_year did not exist\n",
      "Creating end_year table\n",
      "   end_year did not exist\n",
      "Creating runtime table\n",
      "   runtime did not exist\n",
      "Creating num_votes table\n",
      "   num_votes did not exist\n",
      "Creating labels table\n",
      "   labels did not exist\n"
     ]
    }
   ],
   "source": [
    "curr = \"primary_title\"\n",
    "print(f\"Creating {curr} table\")\n",
    "try:\n",
    "    conn.execute('DROP TABLE primary_title')\n",
    "except:\n",
    "    print(f\"   {curr} did not exist\")\n",
    "try:\n",
    "    conn.execute('CREATE TABLE primary_title(tconst_list INTEGER PRIMARY KEY, primary_title VARCHAR)')\n",
    "except Exception as e:\n",
    "    print(f\"   Could not create {curr} with error: {e}\")    \n",
    "\n",
    "curr = \"original_title\"\n",
    "print(f\"Creating {curr} table\")\n",
    "try:\n",
    "    conn.execute('DROP TABLE original_title')\n",
    "except:\n",
    "    print(f\"   {curr} did not exist\")\n",
    "try:\n",
    "    conn.execute('CREATE TABLE original_title(tconst_list INTEGER PRIMARY KEY, original_title VARCHAR)')\n",
    "except Exception as e:\n",
    "    print(f\"   Could not create {curr} with error: {e}\")   \n",
    "    \n",
    "curr = \"start_year\"\n",
    "print(f\"Creating {curr} table\")\n",
    "try:\n",
    "    conn.execute('DROP TABLE start_year')\n",
    "except:\n",
    "    print(f\"   {curr} did not exist\")\n",
    "try:\n",
    "    conn.execute('CREATE TABLE start_year(tconst_list INTEGER PRIMARY KEY, start_year INTEGER)')\n",
    "except Exception as e:\n",
    "    print(f\"   Could not create {curr} with error: {e}\")\n",
    "    \n",
    "curr = \"end_year\"\n",
    "print(f\"Creating {curr} table\")\n",
    "try:\n",
    "    conn.execute('DROP TABLE end_year')\n",
    "except:\n",
    "    print(f\"   {curr} did not exist\")\n",
    "try:\n",
    "    conn.execute('CREATE TABLE end_year(tconst_list INTEGER PRIMARY KEY, end_year INTEGER)')\n",
    "except Exception as e:\n",
    "    print(f\"   Could not create {curr} with error: {e}\")\n",
    "    \n",
    "curr = \"runtime\"\n",
    "print(f\"Creating {curr} table\")\n",
    "try:\n",
    "    conn.execute('DROP TABLE runtime')\n",
    "except:\n",
    "    print(f\"   {curr} did not exist\")\n",
    "try:\n",
    "    conn.execute('CREATE TABLE runtime(tconst_list INTEGER PRIMARY KEY, runtime_minutes INTEGER)')\n",
    "except Exception as e:\n",
    "    print(f\"   Could not create {curr} with error: {e}\")\n",
    "\n",
    "curr = \"num_votes\"\n",
    "print(f\"Creating {curr} table\")\n",
    "try:\n",
    "    conn.execute('DROP TABLE num_votes')\n",
    "except:\n",
    "    print(f\"   {curr} did not exist\")\n",
    "try:\n",
    "    conn.execute('CREATE TABLE num_votes(tconst_list INTEGER PRIMARY KEY, num_votes INTEGER)')\n",
    "except Exception as e:\n",
    "    print(f\"   Could not create {curr} with error: {e}\")\n",
    "    \n",
    "curr = \"labels\"\n",
    "print(f\"Creating {curr} table\")\n",
    "try:\n",
    "    conn.execute('DROP TABLE labels')\n",
    "except:\n",
    "    print(f\"   {curr} did not exist\")\n",
    "try:\n",
    "    conn.execute('CREATE TABLE labels(tconst_list INTEGER PRIMARY KEY, labels BOOLEAN)')\n",
    "except Exception as e:\n",
    "    print(f\"   Could not create {curr} with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end_year', 'labels', 'num_votes', 'original_title', 'primary_title', 'runtime', 'start_year']\n"
     ]
    }
   ],
   "source": [
    "tables = conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       True\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "       ...  \n",
      "988    False\n",
      "989    False\n",
      "990    False\n",
      "991     True\n",
      "992     True\n",
      "Name: label, Length: 7959, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(full_train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corr_labels = full_train_df['label'].values.astype('int')\n",
    "labels = pd.DataFrame(corr_labels, index=full_train_df['tconst'], columns=['labels'])\n",
    "# labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           labels\n",
      "tconst           \n",
      "tt0010600       1\n",
      "tt0011841       1\n",
      "tt0012494       1\n",
      "tt0015163       1\n",
      "tt0016220       1\n",
      "...           ...\n",
      "tt9625664       0\n",
      "tt9741310       0\n",
      "tt9742392       0\n",
      "tt9850386       1\n",
      "tt9911196       1\n",
      "\n",
      "[7959 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# merged_df = pd.concat([primary_title_df, original_title_df, start_year_df, end_year_df, runtime_df], axis=1)\n",
    "merged_df = pd.concat([start_year_df, end_year_df, runtime_df,num_votes_df], axis=1)\n",
    "# merged_df = pd.concat([num_votes_df, runtime_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           start_year  end_year  runtime_minutes  num_votes\n",
      "tconst                                                     \n",
      "tt0010600        1919         0               66     1898.0\n",
      "tt0011841        1920         0              145     5376.0\n",
      "tt0012494        1921         0               97     5842.0\n",
      "tt0015163        1924         0               59     9652.0\n",
      "tt0016220        1925         0               93    17887.0\n",
      "...               ...       ...              ...        ...\n",
      "tt9625664        2019         0               87    12951.0\n",
      "tt9741310        2020         0               77     2464.0\n",
      "tt9742392        2020         0              101     1719.0\n",
      "tt9850386        2020         0              111     4144.0\n",
      "tt9911196        2020         0              103     3242.0\n",
      "\n",
      "[7959 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df)\n",
    "# merged_df = merged_df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>num_votes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tconst</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tt0010600</th>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0011841</th>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>5376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0012494</th>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>5842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0015163</th>\n",
       "      <td>1924</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>9652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0016220</th>\n",
       "      <td>1925</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>17887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9625664</th>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>12951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9741310</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>2464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9742392</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1719.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9850386</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>4144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9911196</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>3242.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_year  end_year  runtime_minutes  num_votes\n",
       "tconst                                                     \n",
       "tt0010600        1919         0               66     1898.0\n",
       "tt0011841        1920         0              145     5376.0\n",
       "tt0012494        1921         0               97     5842.0\n",
       "tt0015163        1924         0               59     9652.0\n",
       "tt0016220        1925         0               93    17887.0\n",
       "...               ...       ...              ...        ...\n",
       "tt9625664        2019         0               87    12951.0\n",
       "tt9741310        2020         0               77     2464.0\n",
       "tt9742392        2020         0              101     1719.0\n",
       "tt9850386        2020         0              111     4144.0\n",
       "tt9911196        2020         0              103     3242.0\n",
       "\n",
       "[7959 rows x 4 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().values.any()\n",
    "merged_df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (6367, 4)\n",
      "y_train: (6367, 1)\n",
      "X_test: (1592, 4)\n",
      "y_test: (1592, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# print(len(merged_df) * 0.8)\n",
    "X_train = merged_df[:6367]\n",
    "X_test = merged_df[6367:]\n",
    "\n",
    "# y_train = labels['labels'][:6367]\n",
    "# y_test = labels['labels'][6367:]\n",
    "y_train = labels[:6367]\n",
    "y_test = labels[6367:]\n",
    "\n",
    "# Check the dimension of the sets\n",
    "print('X_train:',np.shape(X_train))\n",
    "print('y_train:',np.shape(y_train))\n",
    "print('X_test:',np.shape(X_test))\n",
    "print('y_test:',np.shape(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           start_year  end_year  runtime_minutes  num_votes\n",
      "tconst                                                     \n",
      "tt0010600        1919         0               66     1898.0\n",
      "tt0011841        1920         0              145     5376.0\n",
      "tt0012494        1921         0               97     5842.0\n",
      "tt0015163        1924         0               59     9652.0\n",
      "tt0016220        1925         0               93    17887.0\n",
      "...               ...       ...              ...        ...\n",
      "tt0292542        2001         0              123    15380.0\n",
      "tt0298203        2002         0              110   269808.0\n",
      "tt0301050        1999         0               75     1146.0\n",
      "tt0301470        2003         0              106    62519.0\n",
      "tt0303243        2000      2000              102        NaN\n",
      "\n",
      "[6367 rows x 4 columns]\n",
      "           labels\n",
      "tconst           \n",
      "tt0010600       1\n",
      "tt0011841       1\n",
      "tt0012494       1\n",
      "tt0015163       1\n",
      "tt0016220       1\n",
      "...           ...\n",
      "tt0292542       1\n",
      "tt0298203       1\n",
      "tt0301050       1\n",
      "tt0301470       0\n",
      "tt0303243       1\n",
      "\n",
      "[6367 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential   # importing Sequential model\n",
    "from keras.layers import Dense        # importing Dense layers\n",
    "import keras.optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basic_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding layers to the model\n",
    "# First layers: 16 neurons/perceptrons that takes the input and uses 'sigmoid' activation function.\n",
    "basic_model.add(Dense(units = 16 , activation = 'sigmoid', input_shape = (4,))) \n",
    "# Second layer: 1 neuron/perceptron that takes the input from the 1st layers and gives output as 0 or 1.Activation used is 'Hard Sigmoid'\n",
    "basic_model.add(Dense(1, activation = 'hard_sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "basic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/casbertrams/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sgd = tf.keras.optimizers.SGD(lr=0.5, momentum=0.9, nesterov=True)\n",
    "basic_model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "199/199 [==============================] - 0s 925us/step - loss: nan - accuracy: 0.4883\n",
      "Epoch 2/10\n",
      "199/199 [==============================] - 0s 748us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 3/10\n",
      "199/199 [==============================] - 0s 804us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 4/10\n",
      "199/199 [==============================] - 0s 927us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 5/10\n",
      "199/199 [==============================] - 0s 905us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 6/10\n",
      "199/199 [==============================] - 0s 924us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 7/10\n",
      "199/199 [==============================] - 0s 898us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 8/10\n",
      "199/199 [==============================] - 0s 840us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 9/10\n",
      "199/199 [==============================] - 0s 809us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 10/10\n",
      "199/199 [==============================] - 0s 884us/step - loss: nan - accuracy: 0.4878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa38a66d880>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "basic_model.fit(X_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 652us/step - loss: nan - accuracy: 0.5421\n",
      "Loss =  nan\n",
      "Accuracy =  0.5420854091644287\n"
     ]
    }
   ],
   "source": [
    "# Test, Loss and accuracy\n",
    "loss_and_metrics = basic_model.evaluate(X_test, y_test)\n",
    "print('Loss = ',loss_and_metrics[0])\n",
    "print('Accuracy = ',loss_and_metrics[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(4,)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6367/6367 [==============================] - 4s 660us/step - loss: nan - accuracy: 0.4878\n",
      "Epoch 2/50\n",
      "5209/6367 [=======================>......] - ETA: 0s - loss: nan - accuracy: 0.4886"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-344-38dbf41eb931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0moutputs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m     ret = nest.pack_sequence_as(self._func_graph.structured_outputs,\n\u001b[0m\u001b[1;32m   2324\u001b[0m                                 outputs_list, expand_composites=True)\n\u001b[1;32m   2325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m   \"\"\"\n\u001b[0;32m--> 757\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    641\u001b[0m           \u001b[0;34m\"flat_sequence had %d elements.  Structure: %s, flat_sequence: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m           (len(flat_structure), len(flat_sequence), structure, flat_sequence))\n\u001b[0;32m--> 643\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msequence_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_sequence_like\u001b[0;34m(instance, args)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# ordered and plain dicts (e.g., flattening a dict but using a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# corresponding `OrderedDict` to pack it back).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0minstance_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minstance_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=1)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-369-748600aad520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the model on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[0;32m--> 303\u001b[0;31m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
