{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to duckdb and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end_year', 'labels', 'num_votes', 'original_title', 'primary_title', 'runtime', 'start_year', 'test_end_year', 'test_num_votes', 'test_original_title', 'test_primary_title', 'test_runtime', 'test_start_year', 'test_user_ratings', 'user_ratings', 'validation_end_year', 'validation_num_votes', 'validation_original_title', 'validation_primary_title', 'validation_runtime', 'validation_start_year', 'validation_user_ratings']\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect('db/db.duckdb', read_only=False)\n",
    "\n",
    "print(conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN values in the df: True\n"
     ]
    }
   ],
   "source": [
    "tables = conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist()\n",
    "frames = []\n",
    "for i in tables:\n",
    "    if not i.startswith('test') and not i.startswith('validation'):\n",
    "        frames.append(conn.execute(f\"SELECT * FROM {i}\").fetchdf())\n",
    "merged_df = reduce(lambda  left,right: pd.merge(left,right,on=['tconst'], how='outer'), frames)\n",
    "print(f\"Any NaN values in the df: {merged_df.isnull().values.any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7959\n",
      "Any NaN values in the df: True\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df))\n",
    "print(f\"Any NaN values in the df: {merged_df.isnull().values.any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add value to indicate wether the title has been changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = []\n",
    "for i in range(len(merged_df)):\n",
    "    curr_original = merged_df.iloc[i]['original_title']\n",
    "    curr_primary = merged_df.iloc[i]['primary_title']\n",
    "    if curr_original != \"\" and curr_primary != curr_original:\n",
    "        renamed.append(1)\n",
    "    else:\n",
    "        renamed.append(0)\n",
    "    \n",
    "merged_df['renamed'] = renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform dataframe to ML suited data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform dataframe to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tconst              object\n",
      "end_year             int32\n",
      "labels                bool\n",
      "num_votes            int32\n",
      "original_title      object\n",
      "primary_title       object\n",
      "runtime_minutes      int32\n",
      "start_year           int32\n",
      "rating             float64\n",
      "renamed              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.dtypes)\n",
    "merged_df = merged_df.drop('original_title', 1)\n",
    "merged_df = merged_df.drop('primary_title', 1)\n",
    "merged_df = merged_df.drop('tconst', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      end_year  labels  num_votes  runtime_minutes  start_year  rating  \\\n",
      "0            0    True       1898               66        1919     NaN   \n",
      "1            0    True       5376              145        1920     7.0   \n",
      "2            0    True       5842               97        1921     9.0   \n",
      "3            0    True       9652               59        1924     8.0   \n",
      "4            0    True      17887               93        1925     7.0   \n",
      "...        ...     ...        ...              ...         ...     ...   \n",
      "7954         0   False      12951               87        2019     3.0   \n",
      "7955         0   False       2464               77        2020     NaN   \n",
      "7956         0   False       1719              101        2020     6.0   \n",
      "7957         0    True       4144              111        2020     8.0   \n",
      "7958         0    True       3242              103        2020     8.0   \n",
      "\n",
      "      renamed  \n",
      "0           1  \n",
      "1           0  \n",
      "2           1  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "7954        0  \n",
      "7955        0  \n",
      "7956        0  \n",
      "7957        0  \n",
      "7958        1  \n",
      "\n",
      "[7959 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_without_ratings = merged_df.drop('rating', 1)\n",
    "merged_df_with_ratings = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_without_ratings = merged_df_without_ratings['labels']\n",
    "labels_without_ratings = np.array(labels_without_ratings.astype('int').tolist())\n",
    "merged_df_without_ratings = merged_df_without_ratings.drop('labels', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_with_ratings = merged_df_with_ratings['labels']\n",
    "labels_with_ratings = np.array(labels_with_ratings.astype('int').tolist())\n",
    "merged_df_with_ratings = merged_df_with_ratings.drop('labels', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7959\n",
      "7959\n",
      "5540\n",
      "5540\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df_without_ratings))\n",
    "print(len(labels_without_ratings))\n",
    "print(len(merged_df_with_ratings))\n",
    "print(len(labels_with_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_array_without_ratings = merged_df_without_ratings.to_numpy()\n",
    "full_array_with_ratings = merged_df_with_ratings.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7959\n",
      "5540\n"
     ]
    }
   ],
   "source": [
    "print(len(full_array_without_ratings))\n",
    "print(len(full_array_with_ratings))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6367, 5)\n",
      "(6367,)\n",
      "(1592, 5)\n",
      "(1592,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer = StandardScaler()\n",
    "full_array_without_ratings = standardizer.fit_transform(full_array_without_ratings)\n",
    "\n",
    "split = 6367\n",
    "\n",
    "X_train_without_ratings = full_array_without_ratings[:split]\n",
    "y_train_without_ratings = labels_without_ratings[:split]\n",
    "\n",
    "X_test_without_ratings = full_array_without_ratings[split:]\n",
    "y_test_without_ratings = labels_without_ratings[split:]\n",
    "\n",
    "print(X_train_without_ratings.shape)\n",
    "print(y_train_without_ratings.shape)\n",
    "print(X_test_without_ratings.shape)\n",
    "print(y_test_without_ratings.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4432, 6)\n",
      "(4432,)\n",
      "(1108, 6)\n",
      "(1108,)\n"
     ]
    }
   ],
   "source": [
    "full_array_with_ratings = standardizer.fit_transform(full_array_with_ratings)\n",
    "\n",
    "split = 4432\n",
    "\n",
    "X_train_with_ratings = full_array_with_ratings[:split]\n",
    "y_train_with_ratings = labels_with_ratings[:split]\n",
    "\n",
    "X_test_with_ratings = full_array_with_ratings[split:]\n",
    "y_test_with_ratings = labels_with_ratings[split:]\n",
    "\n",
    "print(X_train_with_ratings.shape)\n",
    "print(y_train_with_ratings.shape)\n",
    "print(X_test_with_ratings.shape)\n",
    "print(y_test_with_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.32995896 -0.24666328  1.56608671  0.19767778  0.35489939 -0.37905528]\n",
      " [-0.32995896 -0.2430555  -0.37551326  0.19935816  1.48714391  2.63813762]\n",
      " [-0.32995896 -0.21355846 -1.91261324  0.20439929  0.92102165 -0.37905528]\n",
      " ...\n",
      " [-0.32995896 -0.2882843   1.9705867   0.33714923 -1.90958966  2.63813762]\n",
      " [-0.32995896 -0.25399496 -0.49686326  0.33714923 -0.21122287 -0.37905528]\n",
      " [-0.32995896  2.53056486  0.51438673  0.33882961  0.92102165  2.63813762]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_with_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive(TP)  =  483\n",
      "False Positive(FP) =  82\n",
      "True Negative(TN)  =  492\n",
      "False Negative(FN) =  53\n",
      "Accuracy of the binary classification = 0.878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "accuracy =  (TP+TN) /(TP+FP+TN+FN)\n",
    "\n",
    "print('Accuracy of the binary classification = {:0.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential   # importing Sequential model\n",
    "from keras.layers import Dense        # importing Dense layers\n",
    "import keras.optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basic_model = Sequential()\n",
    "# Adding layers to the model\n",
    "# First layers: 16 neurons/perceptrons that takes the input and uses 'sigmoid' activation function.\n",
    "basic_model.add(Dense(units = 16 , activation = 'sigmoid', input_shape = (6,))) \n",
    "# Second layer: 1 neuron/perceptron that takes the input from the 1st layers and gives output as 0 or 1.Activation used is 'Hard Sigmoid'\n",
    "basic_model.add(Dense(1, activation = 'hard_sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.5, momentum=0.9, nesterov=True)\n",
    "basic_model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "139/139 [==============================] - 0s 856us/step - loss: 0.6814 - accuracy: 0.4497\n",
      "Epoch 2/50\n",
      "139/139 [==============================] - 0s 679us/step - loss: 0.6559 - accuracy: 0.4876\n",
      "Epoch 3/50\n",
      "139/139 [==============================] - 0s 664us/step - loss: 0.6310 - accuracy: 0.5851\n",
      "Epoch 4/50\n",
      "139/139 [==============================] - 0s 643us/step - loss: 0.6114 - accuracy: 0.7014\n",
      "Epoch 5/50\n",
      "139/139 [==============================] - 0s 653us/step - loss: 0.5963 - accuracy: 0.7614\n",
      "Epoch 6/50\n",
      "139/139 [==============================] - 0s 713us/step - loss: 0.5868 - accuracy: 0.7941\n",
      "Epoch 7/50\n",
      "139/139 [==============================] - 0s 767us/step - loss: 0.5803 - accuracy: 0.8167\n",
      "Epoch 8/50\n",
      "139/139 [==============================] - 0s 820us/step - loss: 0.5754 - accuracy: 0.8266\n",
      "Epoch 9/50\n",
      "139/139 [==============================] - 0s 677us/step - loss: 0.5715 - accuracy: 0.8372\n",
      "Epoch 10/50\n",
      "139/139 [==============================] - 0s 642us/step - loss: 0.5684 - accuracy: 0.8429\n",
      "Epoch 11/50\n",
      "139/139 [==============================] - 0s 665us/step - loss: 0.5659 - accuracy: 0.8470\n",
      "Epoch 12/50\n",
      "139/139 [==============================] - 0s 679us/step - loss: 0.5640 - accuracy: 0.8510\n",
      "Epoch 13/50\n",
      "139/139 [==============================] - 0s 711us/step - loss: 0.5623 - accuracy: 0.8517\n",
      "Epoch 14/50\n",
      "139/139 [==============================] - 0s 673us/step - loss: 0.5609 - accuracy: 0.8551\n",
      "Epoch 15/50\n",
      "139/139 [==============================] - 0s 700us/step - loss: 0.5597 - accuracy: 0.8571\n",
      "Epoch 16/50\n",
      "139/139 [==============================] - 0s 754us/step - loss: 0.5586 - accuracy: 0.8596\n",
      "Epoch 17/50\n",
      "139/139 [==============================] - 0s 757us/step - loss: 0.5576 - accuracy: 0.8619\n",
      "Epoch 18/50\n",
      "139/139 [==============================] - 0s 698us/step - loss: 0.5567 - accuracy: 0.8632\n",
      "Epoch 19/50\n",
      "139/139 [==============================] - 0s 659us/step - loss: 0.5559 - accuracy: 0.8652\n",
      "Epoch 20/50\n",
      "139/139 [==============================] - 0s 642us/step - loss: 0.5552 - accuracy: 0.8682\n",
      "Epoch 21/50\n",
      "139/139 [==============================] - 0s 659us/step - loss: 0.5546 - accuracy: 0.8693\n",
      "Epoch 22/50\n",
      "139/139 [==============================] - 0s 641us/step - loss: 0.5541 - accuracy: 0.8686\n",
      "Epoch 23/50\n",
      "139/139 [==============================] - 0s 654us/step - loss: 0.5535 - accuracy: 0.8688\n",
      "Epoch 24/50\n",
      "139/139 [==============================] - 0s 661us/step - loss: 0.5530 - accuracy: 0.8695\n",
      "Epoch 25/50\n",
      "139/139 [==============================] - 0s 679us/step - loss: 0.5527 - accuracy: 0.8704\n",
      "Epoch 26/50\n",
      "139/139 [==============================] - 0s 747us/step - loss: 0.5524 - accuracy: 0.8704\n",
      "Epoch 27/50\n",
      "139/139 [==============================] - 0s 757us/step - loss: 0.5521 - accuracy: 0.8702\n",
      "Epoch 28/50\n",
      "139/139 [==============================] - 0s 707us/step - loss: 0.5518 - accuracy: 0.8707\n",
      "Epoch 29/50\n",
      "139/139 [==============================] - 0s 668us/step - loss: 0.5516 - accuracy: 0.8707\n",
      "Epoch 30/50\n",
      "139/139 [==============================] - 0s 650us/step - loss: 0.5515 - accuracy: 0.8700\n",
      "Epoch 31/50\n",
      "139/139 [==============================] - 0s 648us/step - loss: 0.5513 - accuracy: 0.8704\n",
      "Epoch 32/50\n",
      "139/139 [==============================] - 0s 658us/step - loss: 0.5513 - accuracy: 0.8698\n",
      "Epoch 33/50\n",
      "139/139 [==============================] - 0s 655us/step - loss: 0.5512 - accuracy: 0.8698\n",
      "Epoch 34/50\n",
      "139/139 [==============================] - 0s 685us/step - loss: 0.5511 - accuracy: 0.8700\n",
      "Epoch 35/50\n",
      "139/139 [==============================] - 0s 749us/step - loss: 0.5511 - accuracy: 0.8700\n",
      "Epoch 36/50\n",
      "139/139 [==============================] - 0s 753us/step - loss: 0.5511 - accuracy: 0.8702\n",
      "Epoch 37/50\n",
      "139/139 [==============================] - 0s 728us/step - loss: 0.5511 - accuracy: 0.8700\n",
      "Epoch 38/50\n",
      "139/139 [==============================] - 0s 656us/step - loss: 0.5510 - accuracy: 0.8700\n",
      "Epoch 39/50\n",
      "139/139 [==============================] - 0s 684us/step - loss: 0.5510 - accuracy: 0.8698\n",
      "Epoch 40/50\n",
      "139/139 [==============================] - 0s 649us/step - loss: 0.5510 - accuracy: 0.8700\n",
      "Epoch 41/50\n",
      "139/139 [==============================] - 0s 655us/step - loss: 0.5510 - accuracy: 0.8698\n",
      "Epoch 42/50\n",
      "139/139 [==============================] - 0s 725us/step - loss: 0.5510 - accuracy: 0.8700\n",
      "Epoch 43/50\n",
      "139/139 [==============================] - 0s 764us/step - loss: 0.5510 - accuracy: 0.8700\n",
      "Epoch 44/50\n",
      "139/139 [==============================] - 0s 739us/step - loss: 0.5510 - accuracy: 0.8700\n",
      "Epoch 45/50\n",
      "139/139 [==============================] - 0s 708us/step - loss: 0.5510 - accuracy: 0.8700\n",
      "Epoch 46/50\n",
      "139/139 [==============================] - 0s 725us/step - loss: 0.5510 - accuracy: 0.8700\n",
      "Epoch 47/50\n",
      "139/139 [==============================] - 0s 660us/step - loss: 0.5510 - accuracy: 0.8698\n",
      "Epoch 48/50\n",
      "139/139 [==============================] - 0s 674us/step - loss: 0.5510 - accuracy: 0.8698\n",
      "Epoch 49/50\n",
      "139/139 [==============================] - 0s 717us/step - loss: 0.5510 - accuracy: 0.8698\n",
      "Epoch 50/50\n",
      "139/139 [==============================] - 0s 664us/step - loss: 0.5510 - accuracy: 0.8698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffb234e7580>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "basic_model.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 521us/step - loss: 0.6618 - accuracy: 0.6757\n",
      "Loss =  0.6617915630340576\n",
      "Accuracy =  0.6757082343101501\n"
     ]
    }
   ],
   "source": [
    "# Test, Loss and accuracy\n",
    "loss_and_metrics = basic_model.evaluate(X_test, y_test)\n",
    "print('Loss = ',loss_and_metrics[0])\n",
    "print('Accuracy = ',loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras 2 without ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential   # importing Sequential model\n",
    "from keras.layers import Dense        # importing Dense layers\n",
    "import keras.optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.33100304 -0.22659344 -1.53571186  0.19837533  2.61118194]\n",
      " [-0.33100304 -0.19467699  1.53458386  0.20005195 -0.38296834]\n",
      " [-0.33100304 -0.19040066 -0.33091227  0.20172858  2.61118194]\n",
      " ...\n",
      " [-0.33100304 -0.2334943  -1.18593133  0.33250532 -0.38296834]\n",
      " [-0.33100304  0.32970536  0.01886825  0.33921182 -0.38296834]\n",
      " [ 3.0227923  -0.24401076 -0.13658976 -3.01906779  2.61118194]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_without_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras2model_without_ratings = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(5,)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6367/6367 [==============================] - 6s 812us/step - loss: 0.6110 - accuracy: 0.6717\n",
      "Epoch 2/10\n",
      "6367/6367 [==============================] - 5s 763us/step - loss: 0.5966 - accuracy: 0.6892\n",
      "Epoch 3/10\n",
      "6367/6367 [==============================] - 5s 800us/step - loss: 0.5909 - accuracy: 0.6895\n",
      "Epoch 4/10\n",
      "6367/6367 [==============================] - 5s 859us/step - loss: 0.5804 - accuracy: 0.7027\n",
      "Epoch 5/10\n",
      "6367/6367 [==============================] - 5s 770us/step - loss: 0.5722 - accuracy: 0.7131\n",
      "Epoch 6/10\n",
      "6367/6367 [==============================] - 5s 796us/step - loss: 0.5660 - accuracy: 0.7185\n",
      "Epoch 7/10\n",
      "6367/6367 [==============================] - 5s 806us/step - loss: 0.5602 - accuracy: 0.7209\n",
      "Epoch 8/10\n",
      "6367/6367 [==============================] - 5s 751us/step - loss: 0.5573 - accuracy: 0.7218\n",
      "Epoch 9/10\n",
      "6367/6367 [==============================] - 5s 762us/step - loss: 0.5557 - accuracy: 0.7223\n",
      "Epoch 10/10\n",
      "6367/6367 [==============================] - 5s 798us/step - loss: 0.5514 - accuracy: 0.7245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea9131fd90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras2model_without_ratings.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "keras2model_without_ratings.fit(X_train_without_ratings, y_train_without_ratings, epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 740us/step - loss: 0.6089 - accuracy: 0.6972\n",
      "Loss =  0.6089065074920654\n",
      "Accuracy =  0.697236180305481\n"
     ]
    }
   ],
   "source": [
    "# Test, Loss and accuracy\n",
    "loss_and_metrics = keras2model_without_ratings.evaluate(X_test_without_ratings, y_test_without_ratings)\n",
    "print('Loss = ',loss_and_metrics[0])\n",
    "print('Accuracy = ',loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras 2 with ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential   # importing Sequential model\n",
    "from keras.layers import Dense        # importing Dense layers\n",
    "import keras.optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras2model_with_ratings = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(6,)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4432/4432 [==============================] - 4s 798us/step - loss: 0.3652 - accuracy: 0.8569\n",
      "Epoch 2/10\n",
      "4432/4432 [==============================] - 3s 743us/step - loss: 0.3356 - accuracy: 0.8687\n",
      "Epoch 3/10\n",
      "4432/4432 [==============================] - 3s 730us/step - loss: 0.3273 - accuracy: 0.8705\n",
      "Epoch 4/10\n",
      "4432/4432 [==============================] - 3s 789us/step - loss: 0.3231 - accuracy: 0.8734\n",
      "Epoch 5/10\n",
      "4432/4432 [==============================] - 3s 738us/step - loss: 0.3225 - accuracy: 0.8732\n",
      "Epoch 6/10\n",
      "4432/4432 [==============================] - 3s 728us/step - loss: 0.3163 - accuracy: 0.8741\n",
      "Epoch 7/10\n",
      "4432/4432 [==============================] - 3s 733us/step - loss: 0.3152 - accuracy: 0.8709\n",
      "Epoch 8/10\n",
      "4432/4432 [==============================] - 3s 726us/step - loss: 0.3153 - accuracy: 0.8707\n",
      "Epoch 9/10\n",
      "4432/4432 [==============================] - 3s 701us/step - loss: 0.3103 - accuracy: 0.8755\n",
      "Epoch 10/10\n",
      "4432/4432 [==============================] - 3s 746us/step - loss: 0.3097 - accuracy: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea913a2d90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras2model_with_ratings.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "keras2model_with_ratings.fit(X_train_with_ratings, y_train_with_ratings, epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 791us/step - loss: 0.2732 - accuracy: 0.8881\n",
      "Loss =  0.27319660782814026\n",
      "Accuracy =  0.8880866169929504\n"
     ]
    }
   ],
   "source": [
    "# Test, Loss and accuracy\n",
    "loss_and_metrics = keras2model_with_ratings.evaluate(X_test_with_ratings, y_test_with_ratings)\n",
    "print('Loss = ',loss_and_metrics[0])\n",
    "print('Accuracy = ',loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "# Test, Loss and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846846846846846"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os\n",
    "conn = duckdb.connect('db/db.duckdb', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN values in the df: True\n",
      "tconst               0\n",
      "end_year             0\n",
      "num_votes            0\n",
      "original_title       0\n",
      "primary_title        0\n",
      "runtime_minutes      0\n",
      "start_year           0\n",
      "rating             343\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tables = conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist()\n",
    "frames = []\n",
    "for i in tables:\n",
    "    if i.startswith('test'):\n",
    "        frames.append(conn.execute(f\"SELECT * FROM {i}\").fetchdf())\n",
    "test_merged_df = reduce(lambda  left,right: pd.merge(left,right,on=['tconst'], how='outer'), frames)\n",
    "print(f\"Any NaN values in the df: {test_merged_df.isnull().values.any()}\")\n",
    "print(test_merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN values in the df: True\n",
      "tconst               0\n",
      "end_year             0\n",
      "num_votes            0\n",
      "original_title       0\n",
      "primary_title        0\n",
      "runtime_minutes      0\n",
      "start_year           0\n",
      "rating             306\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tables = conn.execute('PRAGMA show_tables').fetchdf()['name'].tolist()\n",
    "frames = []\n",
    "for i in tables:\n",
    "    if i.startswith('validation'):\n",
    "        frames.append(conn.execute(f\"SELECT * FROM {i}\").fetchdf())\n",
    "validation_merged_df = reduce(lambda  left,right: pd.merge(left,right,on=['tconst'], how='outer'), frames)\n",
    "print(f\"Any NaN values in the df: {validation_merged_df.isnull().values.any()}\")\n",
    "print(validation_merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086\n",
      "1086\n"
     ]
    }
   ],
   "source": [
    "print(len(test_merged_df))\n",
    "bb = pd.read_csv(os.getcwd() + \"/imdb/test_hidden.csv\")\n",
    "print(len(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955\n",
      "955\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_merged_df))\n",
    "dd = pd.read_csv(os.getcwd() + \"/imdb/validation_hidden.csv\")\n",
    "print(len(dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = []\n",
    "for i in range(len(test_merged_df)):\n",
    "    curr_original = test_merged_df.iloc[i]['original_title']\n",
    "    curr_primary = test_merged_df.iloc[i]['primary_title']\n",
    "    if curr_original != \"\" and curr_primary != curr_original:\n",
    "        renamed.append(1)\n",
    "    else:\n",
    "        renamed.append(0)\n",
    "    \n",
    "test_merged_df['renamed'] = renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = []\n",
    "for i in range(len(validation_merged_df)):\n",
    "    curr_original = validation_merged_df.iloc[i]['original_title']\n",
    "    curr_primary = validation_merged_df.iloc[i]['primary_title']\n",
    "    if curr_original != \"\" and curr_primary != curr_original:\n",
    "        renamed.append(1)\n",
    "    else:\n",
    "        renamed.append(0)\n",
    "    \n",
    "validation_merged_df['renamed'] = renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_df = test_merged_df.drop('original_title', 1)\n",
    "test_merged_df = test_merged_df.drop('primary_title', 1)\n",
    "test_merged_df = test_merged_df.drop('tconst', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_merged_df = validation_merged_df.drop('original_title', 1)\n",
    "validation_merged_df = validation_merged_df.drop('primary_title', 1)\n",
    "validation_merged_df = validation_merged_df.drop('tconst', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743 + 343 = 1086\n",
      "649 + 306 = 955\n",
      "743 + 343 = 1086\n",
      "649 + 306 = 955\n"
     ]
    }
   ],
   "source": [
    "test_with_rating_index = np.where(test_merged_df['rating'].notnull())[0]\n",
    "test_without_rating_index = np.where(test_merged_df['rating'].isnull())[0]\n",
    "\n",
    "validation_with_rating_index = np.where(validation_merged_df['rating'].notnull())[0]\n",
    "validation_without_rating_index = np.where(validation_merged_df['rating'].isnull())[0]\n",
    "\n",
    "print(f\"{len(test_with_rating_index)} + {len(test_without_rating_index)} = {len(test_merged_df)}\")\n",
    "print(f\"{len(validation_with_rating_index)} + {len(validation_without_rating_index)} = {len(validation_merged_df)}\")\n",
    "\n",
    "\n",
    "test_with_rating = test_merged_df.iloc[test_with_rating_index]\n",
    "test_without_rating = test_merged_df.iloc[test_without_rating_index]\n",
    "test_without_rating = test_without_rating.drop('rating', 1)\n",
    "print(f\"{len(test_with_rating)} + {len(test_without_rating)} = {len(test_merged_df)}\")\n",
    "\n",
    "validation_with_rating = validation_merged_df.iloc[validation_with_rating_index]\n",
    "validation_without_rating = validation_merged_df.iloc[validation_without_rating_index]\n",
    "validation_without_rating = validation_without_rating.drop('rating', 1)\n",
    "print(f\"{len(validation_with_rating)} + {len(validation_without_rating)} = {len(validation_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n",
      "743\n",
      "306\n",
      "649\n"
     ]
    }
   ],
   "source": [
    "full_test_array_without_ratings = test_without_rating.to_numpy()\n",
    "full_test_array_with_ratings = test_with_rating.to_numpy()\n",
    "\n",
    "full_validation_array_without_ratings = validation_without_rating.to_numpy()\n",
    "full_validation_array_with_ratings = validation_with_rating.to_numpy()\n",
    "\n",
    "print(len(full_test_array_without_ratings))\n",
    "print(len(full_test_array_with_ratings))\n",
    "print(len(full_validation_array_without_ratings))\n",
    "print(len(full_validation_array_with_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer = StandardScaler()\n",
    "full_test_array_without_ratings = standardizer.fit_transform(full_test_array_without_ratings)\n",
    "full_test_array_with_ratings = standardizer.fit_transform(full_test_array_with_ratings)\n",
    "full_validation_array_without_ratings = standardizer.fit_transform(full_validation_array_without_ratings)\n",
    "full_validation_array_with_ratings = standardizer.fit_transform(full_validation_array_with_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n",
      "343\n",
      "743\n",
      "743\n",
      "306\n",
      "306\n",
      "649\n",
      "649\n"
     ]
    }
   ],
   "source": [
    "test_predictions_without_ratings = keras2model_without_ratings.predict(full_test_array_without_ratings)\n",
    "test_predictions_without_ratings = list(map(lambda x: False if x<0.5 else True, test_predictions_without_ratings))\n",
    "\n",
    "test_predictions_with_ratings = keras2model_with_ratings.predict(full_test_array_with_ratings)\n",
    "test_predictions_with_ratings = list(map(lambda x: False if x<0.5 else True, test_predictions_with_ratings))\n",
    "\n",
    "\n",
    "validation_predictions_without_ratings = keras2model_without_ratings.predict(full_validation_array_without_ratings)\n",
    "validation_predictions_without_ratings = list(map(lambda x: False if x<0.5 else True, validation_predictions_without_ratings))\n",
    "\n",
    "\n",
    "validation_predictions_with_ratings = keras2model_with_ratings.predict(full_validation_array_with_ratings)\n",
    "validation_predictions_with_ratings = list(map(lambda x: False if x<0.5 else True, validation_predictions_with_ratings))\n",
    "\n",
    "\n",
    "print(len(test_predictions_without_ratings))\n",
    "print(len(test_without_rating_index))\n",
    "print(len(test_predictions_with_ratings))\n",
    "print(len(test_with_rating_index))\n",
    "print(len(validation_predictions_without_ratings))\n",
    "print(len(validation_without_rating_index))\n",
    "print(len(validation_predictions_with_ratings))\n",
    "print(len(validation_with_rating_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086\n",
      "955\n"
     ]
    }
   ],
   "source": [
    "test_predictions_without_ratings_df = pd.DataFrame(test_predictions_without_ratings, index=test_without_rating_index)\n",
    "test_predictions_with_ratings_df = pd.DataFrame(test_predictions_with_ratings, index=test_with_rating_index)\n",
    "\n",
    "validation_predictions_without_ratings_df = pd.DataFrame(validation_predictions_without_ratings, index=validation_without_rating_index)\n",
    "validation_predictions_with_ratings_df = pd.DataFrame(validation_predictions_with_ratings, index=validation_with_rating_index)\n",
    "\n",
    "\n",
    "final_test_predictions = pd.concat([test_predictions_without_ratings_df, test_predictions_with_ratings_df], axis=0).sort_index()[0].tolist()\n",
    "final_validation_predictions = pd.concat([validation_predictions_without_ratings_df, validation_predictions_with_ratings_df], axis=0).sort_index()[0].tolist()\n",
    "\n",
    "print(len(final_test_predictions))\n",
    "print(len(final_validation_predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     498\n",
      "False    457\n",
      "Name: label, dtype: int64\n",
      "True     549\n",
      "False    537\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_merged_df['label'] = final_validation_predictions\n",
    "print(validation_merged_df['label'].value_counts())\n",
    "\n",
    "test_merged_df['label'] = final_test_predictions\n",
    "print(test_merged_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_predictions4.txt', 'w') as f:\n",
    "    for item in final_test_predictions:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_predictions4.txt', 'w') as f:\n",
    "    for item in final_validation_predictions:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
